<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code examples | Spatial Data in R</title>
    <link>http://isdrfall21.classes.spaseslab.com/example/</link>
      <atom:link href="http://isdrfall21.classes.spaseslab.com/example/index.xml" rel="self" type="application/rss+xml" />
    <description>Code examples</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 21 Oct 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://isdrfall21.classes.spaseslab.com/media/icon_hucbe598379047767cc1c1c9b182811605_98018_512x512_fill_lanczos_center_3.png</url>
      <title>Code examples</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/</link>
    </image>
    
    <item>
      <title>Static maps in R</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/07-example/</link>
      <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/07-example/</guid>
      <description>&lt;h2 id=&#34;loading-the-data&#34;&gt;Loading the data&lt;/h2&gt;
&lt;p&gt;We are going to use the database that we built last week as the starting place for making some static maps this week. We&amp;rsquo;ll load that here along with some new (at least for this course) packages. The &lt;a href=&#34;https://github.com/dkahle/ggmap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;ggmap&lt;/code&gt; package&lt;/a&gt; allows easy downloads of basemaps from Google (requires a key) and Stamen for use in mapping (and within &lt;code&gt;ggplot2&lt;/code&gt;). The &lt;a href=&#34;https://cran.r-project.org/web/packages/cartogram/readme/README.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;cartogram&lt;/code&gt; package&lt;/a&gt; facilitates thematic changes of the geometry based on other attributes (e.g., population). The &lt;a href=&#34;https://patchwork.data-imaginist.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;patchwork&lt;/code&gt; package&lt;/a&gt; allows easy composition of multi-figure plots. I&amp;rsquo;m not going to be able to demonstrate the full capabilities of these packages in one example, but their webpages have tons of useful information. You should check those out!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.3     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.0     ✓ forcats 0.5.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(pander)
library(sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linking to GEOS 3.8.1, GDAL 3.2.1, PROJ 7.2.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(terra)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## terra version 1.3.22
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;terra&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:pander&#39;:
## 
##     wrap
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:dplyr&#39;:
## 
##     src
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(units)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## udunits database from /Library/Frameworks/R.framework/Versions/4.1/Resources/library/units/share/udunits/udunits2.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggmap)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Google&#39;s Terms of Service: https://cloud.google.com/maps-platform/terms/.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Please cite ggmap if you use it! See citation(&amp;quot;ggmap&amp;quot;) for details.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;ggmap&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:terra&#39;:
## 
##     inset
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(cartogram)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;cartogram&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:terra&#39;:
## 
##     cartogram
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(patchwork)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;patchwork&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:terra&#39;:
## 
##     area
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tmap)
library(viridis)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: viridisLite
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;landval &amp;lt;- terra::rast(&#39;/Users/matthewwilliamson/Downloads/session04/idval.tif&#39;)
#landval &amp;lt;- rast(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/Regval.tif&#39;)
#mammal.rich &amp;lt;- rast(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/Mammals_total_richness.tif&#39;)
mammal.rich &amp;lt;- rast(&#39;/Users/matthewwilliamson/Downloads/session16/Mammals_total_richness.tif&#39;)
mammal.rich &amp;lt;- catalyze(mammal.rich) #rmemeber we had to get the layer we wanted from the richness data
mammal.rich &amp;lt;- mammal.rich[[2]]

#pas.desig &amp;lt;- st_read(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session04/regionalPAs1.shp&#39;)
pas.desig &amp;lt;- st_read(&#39;/Users/matthewwilliamson/Downloads/session04/regionalPAs1.shp&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `regionalPAs1&#39; from data source 
##   `/Users/matthewwilliamson/Downloads/session04/regionalPAs1.shp&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 224 features and 7 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -1714157 ymin: 1029431 xmax: -621234.8 ymax: 3043412
## Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pas.proc &amp;lt;- st_read(&#39;/Users/matthewwilliamson/Downloads/session16/reg_pas.shp&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `reg_pas&#39; from data source 
##   `/Users/matthewwilliamson/Downloads/session16/reg_pas.shp&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 544 features and 32 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -2034299 ymin: 1004785 xmax: -530474 ymax: 3059862
## Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#pas.proc &amp;lt;- st_read(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/reg_pas.shp&#39;)
#combine the pas into 1, but the columns don&#39;t all match, thanks PADUS

colnames(pas.proc)[c(1, 6, 8, 10, 12, 22, 25)] &amp;lt;- colnames(pas.desig) #find the columnames in the proc dataset and replace them with the almost matching names from the des.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in colnames(pas.proc)[c(1, 6, 8, 10, 12, 22, 25)] &amp;lt;-
## colnames(pas.desig): number of items to replace is not a multiple of replacement
## length
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gap.sts &amp;lt;- c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;) 
pas &amp;lt;- pas.proc %&amp;gt;% 
  select(., colnames(pas.desig)) %&amp;gt;% 
  bind_rows(pas.desig, pas.proc) %&amp;gt;%  #select the columns that match and then combine
  filter(., State_Nm == &amp;quot;ID&amp;quot; &amp;amp; GAP_Sts %in% gap.sts ) %&amp;gt;% st_make_valid() %&amp;gt;% st_buffer(., 10000)
#Buffering here to deal with some of the linear features along rivers
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;making-a-map-of-idaho&#34;&gt;Making a map of Idaho&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;re going to focus on Idaho in the example (you&amp;rsquo;ll focus on the West for your homework) so we&amp;rsquo;ll need a shapefile to make sure we&amp;rsquo;ve got coverage across the state.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id &amp;lt;- tigris::states(cb=TRUE) %&amp;gt;% 
  filter(STUSPS == &amp;quot;ID&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s get everything into the same projection to save some hassle down the road. Because the mammal richness data is the largest, we&amp;rsquo;ll project everything to that and then crop.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(mammal.rich)$proj4string
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(landval)$proj4string
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(pas)$proj4string
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.vect &amp;lt;- as(pas, &amp;quot;SpatVector&amp;quot;)
id.vect &amp;lt;- as(id, &amp;quot;SpatVector&amp;quot;)

pa.vect &amp;lt;- project(pa.vect, mammal.rich)
id.vect &amp;lt;- project(id.vect, mammal.rich)

land.val.proj &amp;lt;- project(landval, mammal.rich)

mam.rich.crop &amp;lt;- crop(mammal.rich, id.vect)
id.val.crop &amp;lt;- crop(land.val.proj, id.vect)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&amp;rsquo;ll also add population to our census data by making a change to our &lt;code&gt;tidycensus&lt;/code&gt; call (remember that you&amp;rsquo;ll need your Census API key to use &lt;code&gt;tidycensus&lt;/code&gt; (details &lt;a href=&#34;https://walker-data.com/tidycensus/articles/basic-usage.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;). Notice that we also use &lt;code&gt;spread&lt;/code&gt; here to move the data into wide format. Let&amp;rsquo;s do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.census &amp;lt;- tidycensus:: get_acs(geography = &amp;quot;county&amp;quot;, 
              variables = c(medianincome = &amp;quot;B19013_001&amp;quot;,
                            pop = &amp;quot;B01003_001&amp;quot;),
              state = c(&amp;quot;ID&amp;quot;, &amp;quot;MT&amp;quot;), 
              year = 2018,
              key = key,
              geometry = TRUE) %&amp;gt;% 
                st_transform(., crs(pa.vect)) %&amp;gt;% 
  select(-moe) %&amp;gt;% 
  spread(variable, estimate)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we&amp;rsquo;ll do the necessary extractions and join everything together into a single dataframe that we can use for plotting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.summary &amp;lt;- st_join(st_as_sf(pa.vect), id.census, join = st_overlaps)

pa.summary &amp;lt;- pa.summary %&amp;gt;% 
  group_by(Unit_Nm) %&amp;gt;% 
  summarize(., meaninc = mean(medianincome, na.rm=TRUE),
            meanpop = mean(pop, na.rm=TRUE))
#double check to see that I got the right number of rows
nrow(pa.summary) ==length(unique(pas$Unit_Nm))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.zones &amp;lt;- terra::rasterize(pa.vect, mam.rich.crop, field = &amp;quot;Unit_Nm&amp;quot;)
mammal.zones &amp;lt;- terra::zonal(mam.rich.crop, pa.zones, fun = &amp;quot;mean&amp;quot;, na.rm=TRUE)
landval.zones &amp;lt;- terra::zonal(id.val.crop, pa.zones, fun = &amp;quot;mean&amp;quot;, na.rm=TRUE)
#Note that there is one few zone than we have in our PA dataset. This is because we have an overlapping jurisdicition; we&#39;ll ingnore that now but it&#39;s a common problement with using the PADUS

summary.df &amp;lt;- pa.summary %&amp;gt;% 
  left_join(., mammal.zones) %&amp;gt;% 
  left_join(., landval.zones)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;Unit_Nm&amp;quot;
## Joining, by = &amp;quot;Unit_Nm&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#You will have some NAs here owing to the strange nature of the PADUS
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;building-a-quick-map&#34;&gt;Building a quick map&lt;/h2&gt;
&lt;p&gt;Up until now, we&amp;rsquo;ve been using the &lt;code&gt;base::plot&lt;/code&gt; function to generate rapid visualizations of our data. That&amp;rsquo;s fine, but it takes a fair amount of work to get those graphics into something resembling a publication-quality map. The &lt;code&gt;tmap&lt;/code&gt; package is a versatile package designed specifically for making thematic maps. It generally builds on the  grammar of graphics logic and follows most of the &lt;code&gt;ggplot2&lt;/code&gt; conventions. It&amp;rsquo;s not quite as flexible as &lt;code&gt;ggplot2&lt;/code&gt; and doesn&amp;rsquo;t allow easy integration for different types of non-spatial figures (but see &lt;code&gt;patchwork&lt;/code&gt; for ways to address this); however, it has a lot of functionality for both static and interactive mapping and deals with raster datasets in a way that is more intuitive than &lt;code&gt;ggplot2&lt;/code&gt;. I&amp;rsquo;ll introduce a few of the features here, but I would encourage you to take a look at &lt;a href=&#34;https://mgimond.github.io/Spatial/mapping-data-in-r.html#tmap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Manuel Gimond&amp;rsquo;s set of notes&lt;/a&gt; and the &lt;a href=&#34;https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;tmap&lt;/code&gt;&lt;/a&gt; intro pages to get broader exposure to the capabilities of &lt;code&gt;tmap&lt;/code&gt;. We&amp;rsquo;ll revisit some of these next week, but let&amp;rsquo;s get started with some simple examples.&lt;/p&gt;
&lt;h3 id=&#34;a-simple-example&#34;&gt;A simple example&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tm_shape(summary.df) + tm_polygons(col = &amp;quot;meanpop&amp;quot;,  border.col = &amp;quot;white&amp;quot;) + 
  tm_legend(outside = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/tmpex1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t particularly pretty or (even useful), but let&amp;rsquo;s take a look at a few things. The &lt;code&gt;tm_shape&lt;/code&gt; specifies which dataset we are talking about (the data component of the grammar of graphics[gg]). The &lt;code&gt;tm_polygons&lt;/code&gt; call allows you to specify a number of additional gg elements including the aesthetics (here we are telling &lt;code&gt;R&lt;/code&gt; that colors should be assigned based on the &lt;code&gt;meanpop&lt;/code&gt; variable, but that border colors are a fixed value), the geometric object to be used (polygons - specified by &lt;code&gt;tm_polygons&lt;/code&gt;, but there are a variety of &lt;code&gt;tm_*&lt;/code&gt; functions that can be used). You can also specify a number of additional map elements within the &lt;code&gt;tm_shape&lt;/code&gt; function call or use things like &lt;code&gt;tm_legend&lt;/code&gt; to exert more control. See &lt;code&gt;?tm_shape&lt;/code&gt; for a full description. Let&amp;rsquo;s add a state boundary and a raster before moving on.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tm_shape(mam.rich.crop) +
  tm_raster(&amp;quot;Value&amp;quot;, palette = viridis(n=50), n=50, legend.show=FALSE, legend.hist = TRUE, legend.hist.title = &amp;quot;Species Richness&amp;quot;) +
tm_shape(id) +
  tm_borders(&amp;quot;white&amp;quot;, lwd = .75) +
tm_shape(summary.df) +
  tm_polygons(col = &amp;quot;meanpop&amp;quot;,  border.col = &amp;quot;white&amp;quot;, title=&amp;quot;Mean Population&amp;quot;) + 
  tm_legend(outside = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/tmpex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here again we are using the &lt;code&gt;tm_shape&lt;/code&gt; call to specify which data we are talking about, then assigning aesthetics for that data based on &lt;code&gt;tm_raster&lt;/code&gt; and &lt;code&gt;tm_shape&lt;/code&gt;. Notice that you can control whether a particular item appears in the legend with the &lt;code&gt;legend.show&lt;/code&gt; option and that you can change palettes (here using &lt;code&gt;viridis&lt;/code&gt;) to link data values to color values. Notice the use of &lt;code&gt;+&lt;/code&gt; as a way of adding layers and aesthetics.This is also how &lt;code&gt;ggplot2&lt;/code&gt; works. We&amp;rsquo;ll return to that in a moment.&lt;/p&gt;
&lt;h2 id=&#34;building-a-choropleth-map-with-the-grammar-of-graphics&#34;&gt;Building a choropleth map with the grammar of graphics&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;tmap&lt;/code&gt; approach is relatively straigtforward and may achieve all you ever hope for in map production. That said, &lt;code&gt;ggplot2&lt;/code&gt; is generally the &amp;ldquo;industry standard&amp;rdquo; for plotting in &lt;code&gt;R&lt;/code&gt;. That doesn&amp;rsquo;t mean it&amp;rsquo;s the best, or the easiest; but it is under constant development to accomodate more and more different kinds of data. Let&amp;rsquo;s start with a simple example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(summary.df) +
  geom_sf(mapping = aes(fill = meaninc))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/gg1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Just like the &lt;code&gt;tmap&lt;/code&gt;, but with some different defaults! Note here that &lt;code&gt;mapping = aes()&lt;/code&gt; is the call that specifies the mapping between the data and the aesthetics (In this case, we want the fill of the polygons to be based on the mean income). The &lt;code&gt;geom_&lt;/code&gt; call specifies the geometric element. In this case, &lt;code&gt;geom_sf()&lt;/code&gt; lets &lt;code&gt;ggplot2&lt;/code&gt; know that &lt;code&gt;mapping=aes(x= longitude, y=lattitude)&lt;/code&gt;. We can add another layer similar to how we did with &lt;code&gt;tmap&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(summary.df) +
  geom_sf(mapping = aes(fill = meaninc)) +
  geom_sf(data=id, fill=NA,color=&amp;quot;black&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/gg2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we&amp;rsquo;ve added a second call to &lt;code&gt;geom_sf&lt;/code&gt; and added our Idaho shapefile. This time we don&amp;rsquo;t want to map any of the data beyond the geometry to an aesthetic so we leave out the &lt;code&gt;mapping&lt;/code&gt; argument and set the &lt;code&gt;fill&lt;/code&gt; and &lt;code&gt;color&lt;/code&gt; to single values. Now let&amp;rsquo;s add a little fanciness by adding a basemap from &lt;code&gt;ggmap&lt;/code&gt; (check out the &lt;code&gt;?ggmap&lt;/code&gt; and &lt;code&gt;?get_map&lt;/code&gt; for details):&lt;/p&gt;
&lt;h3 id=&#34;adding-a-basemap&#34;&gt;Adding a basemap&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;bg &amp;lt;- ggmap::get_map(as.vector(st_bbox(id)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/22/43.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/23/43.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/24/43.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/22/44.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/23/44.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/24/44.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/22/45.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/23/45.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/24/45.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/22/46.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/23/46.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/24/46.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/22/47.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/23/47.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source : http://tile.stamen.com/terrain/7/24/47.png
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggmap(bg) +
   geom_sf(data = summary.df, mapping = aes(fill = meaninc), inherit.aes = FALSE) +
  geom_sf(data=id, fill=NA,color=&amp;quot;black&amp;quot;, inherit.aes = FALSE) +
  coord_sf(crs = st_crs(4326))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Coordinate system already present. Adding new coordinate system, which will replace the existing one.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/gg3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We are still building the map layer-by-layer, but in this case had to use &lt;code&gt;ggmap&lt;/code&gt; to get &lt;code&gt;R&lt;/code&gt; to recognize that we wanted to use the downloaded file as the base for the plot. We also have to use &lt;code&gt;inherit.aes=FALSE&lt;/code&gt; to allow each additional &lt;code&gt;geom&lt;/code&gt; to have it&amp;rsquo;s own set of aesthetics. Finally, we use &lt;code&gt;coord_sf()&lt;/code&gt; to add a new coordinate system to the map because ggmap downloads everything in WGS84.&lt;/p&gt;
&lt;h3 id=&#34;changing-scales&#34;&gt;Changing Scales&lt;/h3&gt;
&lt;p&gt;Now that we have things starting to look nice, let&amp;rsquo;s see if we can add a few more aesthetics and introduce a scale&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggmap(bg) +
  geom_sf(data = summary.df, mapping = aes(fill = Value, 
                                           alpha = (idval - max(idval, na.rm=TRUE))/(max(idval, na.rm=TRUE)-min(idval, na.rm = TRUE))), inherit.aes = FALSE) +
  geom_sf(data=id, fill=NA,color=&amp;quot;black&amp;quot;, inherit.aes = FALSE) +
  scale_fill_viridis(option=&amp;quot;magma&amp;quot;)+
  coord_sf(crs = st_crs(4326))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Coordinate system already present. Adding new coordinate system, which will replace the existing one.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/gg4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we&amp;rsquo;ve added an additional aesthetic mapping for &lt;code&gt;alpha&lt;/code&gt; which sets the transparency and then used &lt;code&gt;scale_fill_viridis_&lt;/code&gt; to map the species richness value to the viridis color palette. We&amp;rsquo;ve then &amp;lsquo;softened&amp;rsquo; that color based on the cost of land in that area. You can find additional palettes and options using the &lt;code&gt;?scale_fill_&lt;/code&gt; helpfiles.&lt;/p&gt;
&lt;h2 id=&#34;building-a-cartogram&#34;&gt;Building a cartogram&lt;/h2&gt;
&lt;p&gt;One of the beauties of teaching a class like this is it gives me the chance to do something I don&amp;rsquo;t usually get to do. In this case, that thing is drawing cartograms. Let&amp;rsquo;s look at two versions of Idaho using the &lt;code&gt;cartogram&lt;/code&gt; package: population vs. income.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id_pop &amp;lt;- cartogram_cont(id.census, &amp;quot;pop&amp;quot;, itermax = 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 1: 4.81793622368303
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 2: 4.00848667518635
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 3: 3.34903616842005
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 4: 2.79937191745082
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 5: 2.34932232913512
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id_inc &amp;lt;- cartogram_cont(id.census, &amp;quot;medianincome&amp;quot;, itermax = 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 1: 1.86126345506573
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 2: 1.46673557062935
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 3: 1.26459996079085
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 4: 1.15581249947152
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Mean size error for iteration 5: 1.09513236018306
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tm_shape(id_pop) + tm_polygons(&amp;quot;pop&amp;quot;, style = &amp;quot;jenks&amp;quot;) +
  tm_layout(frame = FALSE, legend.position = c(&amp;quot;left&amp;quot;, &amp;quot;bottom&amp;quot;)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/carto-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tm_shape(id_inc) + tm_polygons(&amp;quot;medianincome&amp;quot;, style = &amp;quot;jenks&amp;quot;) +
  tm_layout(frame = FALSE, legend.position = c(&amp;quot;left&amp;quot;, &amp;quot;bottom&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/07-example_files/figure-html/carto-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Kind of interesting to see how the &amp;lsquo;center of gravity&amp;rsquo; in Idaho shifts when we think about population and income. There&amp;rsquo;s lots of additional cartogram options that you can explore. Check out the &lt;a href=&#34;https://cran.r-project.org/web/packages/cartogram/readme/README.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;package page&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Combining raster and vector data</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/06-example/</link>
      <pubDate>Wed, 13 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/06-example/</guid>
      <description>&lt;p&gt;Often when we build our databases for analyses, we&amp;rsquo;ll be working with both vector and raster data models. This creates two issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It&amp;rsquo;s not easy (or often possible) to perform calculations across data models&lt;/li&gt;
&lt;li&gt;Many statistical algorithms expect dataframes with dependent and independent variables which makes working with rasters particularly tricky.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Today we&amp;rsquo;ll look at a few ways to bring these two data models together to develop a dataset for analysis.&lt;/p&gt;
&lt;h2 id=&#34;load-your-libraries-and-the-data&#34;&gt;Load your libraries and the data&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s bring in the data. You should recognize the regional PA dataset and the land value dataset as we&amp;rsquo;ve been working with them a fair amount the last few weeks. The dataset you may not recognize is the species richness dataset (here, for mammals). These data come from a series of studies led by Clinton Jenkins and available &lt;a href=&#34;https://biodiversitymapping.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Let&amp;rsquo;s read them in here.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.5     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.2     ✓ forcats 0.5.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(pander)
library(sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linking to GEOS 3.8.1, GDAL 3.2.1, PROJ 7.2.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(terra)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## terra version 1.4.14
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;terra&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:pander&#39;:
## 
##     wrap
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:dplyr&#39;:
## 
##     src
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:tidyr&#39;:
## 
##     extract
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(units)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## udunits database from /Library/Frameworks/R.framework/Versions/4.0/Resources/library/units/share/udunits/udunits2.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(purrr)
library(sp)
library(profvis)
#landval &amp;lt;- terra::rast(&#39;/Users/matthewwilliamson/Downloads/session04/idval.tif&#39;)
landval &amp;lt;- rast(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/Regval.tif&#39;)
mammal.rich &amp;lt;- rast(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/Mammals_total_richness.tif&#39;)
#mammal.rich &amp;lt;- rast(&#39;/Users/matthewwilliamson/Downloads/session16/Mammals_total_richness.tif&#39;)
pas.desig &amp;lt;- st_read(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session04/regionalPAs1.shp&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `regionalPAs1&#39; from data source 
##   `/Volumes/GoogleDrive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session04/regionalPAs1.shp&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 224 features and 7 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -1714157 ymin: 1029431 xmax: -621234.8 ymax: 3043412
## Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#pas.desig &amp;lt;- st_read(&#39;/Users/matthewwilliamson/Downloads/session04/regionalPAs1.shp&#39;)
#pas.proc &amp;lt;- st_read(&#39;/Users/matthewwilliamson/Downloads/session16/reg_pas.shp&#39;)
pas.proc &amp;lt;- st_read(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/reg_pas.shp&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `reg_pas&#39; from data source 
##   `/Volumes/GoogleDrive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session16/reg_pas.shp&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 544 features and 32 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -2034299 ymin: 1004785 xmax: -530474 ymax: 3059862
## Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#combine the pas into 1, but the columns don&#39;t all match, thanks PADUS

colnames(pas.proc)[c(1, 6, 8, 10, 12, 22, 25)] &amp;lt;- colnames(pas.desig) #find the columnames in the proc dataset and replace them with the almost matching names from the des.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in colnames(pas.proc)[c(1, 6, 8, 10, 12, 22, 25)] &amp;lt;-
## colnames(pas.desig): number of items to replace is not a multiple of replacement
## length
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pas &amp;lt;- pas.proc %&amp;gt;% 
  select(., colnames(pas.desig)) %&amp;gt;% 
  bind_rows(pas.desig, pas.proc) #select the columns that match and then combine
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because we haven&amp;rsquo;t looked at the species richness data yet, let&amp;rsquo;s plot it here.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(mammal.rich)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/06-example_files/figure-html/mamplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ooof. Not pretty. That&amp;rsquo;s because this data is stored as a catgorical raster displaying the count of species contained within each 10km grid cell. Often we are interested in knowing more than just how many species occur. We&amp;rsquo;d rather know something about how many speices and how rare they are. That data is also contained here and we can get it using &lt;code&gt;terra::catalyze&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mammal.rich &amp;lt;- catalyze(mammal.rich)
plot(mammal.rich)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/06-example_files/figure-html/mamcat-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When we plot the data we see that the &amp;ldquo;Value&amp;rdquo; raster contains the informaiton we are looking for (the number of species weighted by their regional rarity). Lets take that and leave the rest.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mammal.rich &amp;lt;- mammal.rich[[2]]
plot(mammal.rich)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/06-example_files/figure-html/mamassign-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Before we move on into our analysis phase. Let&amp;rsquo;s double check the CRS of our data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(mammal.rich)$proj4string
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(landval)$proj4string
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(pas)$proj4string
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alhtough the PAs and land value rasters match, the mammal richness is in a different project. We&amp;rsquo;ll deal with that once we&amp;rsquo;ve subsetted the data a bit.&lt;/p&gt;
&lt;h2 id=&#34;filter-the-data&#34;&gt;Filter the data&lt;/h2&gt;
&lt;p&gt;You&amp;rsquo;ll need to filter the PADUS dataset so that it only contains the &lt;a href=&#34;https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-data-overview?qt-science_center_objects=0#qt-science_center_objects&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gap Status 1&lt;/a&gt; protected areas. Here, I&amp;rsquo;ll do it for Idaho. Note that the PADUS breaks PAs out by how they were created so we need to combine both the designated and proclaimed areas in the data load coad.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.gap.1 &amp;lt;- pas %&amp;gt;% 
  filter(., State_Nm == &amp;quot;ID&amp;quot; &amp;amp; GAP_Sts == &amp;quot;1&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;get-the-data-for-median-income-by-county&#34;&gt;Get the data for median income by county&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s get the median income data and geometry for each county. We&amp;rsquo;ll use the tidycensus package for that. Note that you may have to sign up for a Census Api before you can use the tidycensus package (&lt;a href=&#34;https://walker-data.com/tidycensus/articles/basic-usage.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;instructions here&lt;/a&gt;)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.income &amp;lt;- tidycensus:: get_acs(geography = &amp;quot;county&amp;quot;, 
              variables = c(medianicome = &amp;quot;B19013_001&amp;quot;),
              state = &amp;quot;ID&amp;quot;, 
              year = 2018,
              key = key,
              geometry = TRUE) %&amp;gt;% 
                st_transform(., st_crs(pas))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Getting data from the 2014-2018 5-year ACS
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Downloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |                                                                      |   1%
  |                                                                            
  |=                                                                     |   1%
  |                                                                            
  |=                                                                     |   2%
  |                                                                            
  |==                                                                    |   2%
  |                                                                            
  |==                                                                    |   3%
  |                                                                            
  |==                                                                    |   4%
  |                                                                            
  |===                                                                   |   4%
  |                                                                            
  |===                                                                   |   5%
  |                                                                            
  |====                                                                  |   5%
  |                                                                            
  |====                                                                  |   6%
  |                                                                            
  |=====                                                                 |   7%
  |                                                                            
  |=====                                                                 |   8%
  |                                                                            
  |======                                                                |   8%
  |                                                                            
  |======                                                                |   9%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |========                                                              |  11%
  |                                                                            
  |========                                                              |  12%
  |                                                                            
  |=========                                                             |  12%
  |                                                                            
  |=========                                                             |  13%
  |                                                                            
  |==========                                                            |  14%
  |                                                                            
  |==========                                                            |  15%
  |                                                                            
  |===========                                                           |  15%
  |                                                                            
  |===========                                                           |  16%
  |                                                                            
  |============                                                          |  16%
  |                                                                            
  |============                                                          |  17%
  |                                                                            
  |=============                                                         |  18%
  |                                                                            
  |=============                                                         |  19%
  |                                                                            
  |==============                                                        |  19%
  |                                                                            
  |==============                                                        |  20%
  |                                                                            
  |===============                                                       |  21%
  |                                                                            
  |===============                                                       |  22%
  |                                                                            
  |================                                                      |  23%
  |                                                                            
  |================                                                      |  24%
  |                                                                            
  |=================                                                     |  24%
  |                                                                            
  |=================                                                     |  25%
  |                                                                            
  |==================                                                    |  25%
  |                                                                            
  |==================                                                    |  26%
  |                                                                            
  |===================                                                   |  26%
  |                                                                            
  |============================                                          |  40%
  |                                                                            
  |=============================                                         |  41%
  |                                                                            
  |=============================                                         |  42%
  |                                                                            
  |==============================                                        |  42%
  |                                                                            
  |==============================                                        |  43%
  |                                                                            
  |==============================                                        |  44%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |======================================                                |  54%
  |                                                                            
  |======================================                                |  55%
  |                                                                            
  |=======================================                               |  55%
  |                                                                            
  |=======================================                               |  56%
  |                                                                            
  |========================================                              |  57%
  |                                                                            
  |================================================                      |  69%
  |                                                                            
  |=================================================                     |  70%
  |                                                                            
  |=================================================                     |  71%
  |                                                                            
  |==================================================                    |  71%
  |                                                                            
  |===================================================                   |  72%
  |                                                                            
  |===================================================                   |  73%
  |                                                                            
  |====================================================                  |  75%
  |                                                                            
  |===========================================================           |  84%
  |                                                                            
  |===========================================================           |  85%
  |                                                                            
  |============================================================          |  85%
  |                                                                            
  |============================================================          |  86%
  |                                                                            
  |=============================================================         |  87%
  |                                                                            
  |=============================================================         |  88%
  |                                                                            
  |==============================================================        |  89%
  |                                                                            
  |===============================================================       |  89%
  |                                                                            
  |===============================================================       |  90%
  |                                                                            
  |================================================================      |  91%
  |                                                                            
  |=================================================================     |  93%
  |                                                                            
  |===================================================================   |  96%
  |                                                                            
  |====================================================================  |  96%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |===================================================================== |  99%
  |                                                                            
  |======================================================================| 100%
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-a-spatial-join&#34;&gt;Use a spatial join&lt;/h2&gt;
&lt;p&gt;Use &lt;code&gt;st_join&lt;/code&gt; to connect your PAs dataset with every county within 50km and then use &lt;code&gt;group_by&lt;/code&gt; and &lt;code&gt;summarise&lt;/code&gt; to take the mean value of the median income data for each PA. By the time you are done with this step you should have the same number of rows that you had after your initial filter of the PAs (step 2).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.income &amp;lt;- st_join(id.gap.1, id.income, join = st_is_within_distance, dist=50000)

pa.income.summary &amp;lt;- pa.income %&amp;gt;% 
  group_by(Unit_Nm) %&amp;gt;% 
  summarize(., meaninc = mean(estimate))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;buffer-your-pas&#34;&gt;Buffer your PAs&lt;/h2&gt;
&lt;p&gt;In order to get the raster data from the same area that you just estimated median income, you&amp;rsquo;ll need to buffer the PAs by 50km&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.buf &amp;lt;- id.gap.1 %&amp;gt;% 
  st_buffer(., 50000)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;crop-all-of-the-rasters-to-the-extent-of-your-buffered-pa-dataset&#34;&gt;Crop all of the rasters to the extent of your buffered PA dataset&lt;/h2&gt;
&lt;p&gt;Before you start doing a bunch of raster processing you&amp;rsquo;ll want to get rid of the parts you don&amp;rsquo;t need. Do that here. Remember you&amp;rsquo;ll want all of your rasters to have the same CRS. We won&amp;rsquo;t do that here (but you probably know how to do it)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.buf.vect &amp;lt;- as(pa.buf, &amp;quot;SpatVector&amp;quot;)

mam.rich.crop &amp;lt;- crop(mammal.rich, project(pa.buf.vect, mammal.rich))
id.val.crop &amp;lt;- crop(landval, project(pa.buf.vect, landval))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extract-the-data&#34;&gt;Extract the data&lt;/h2&gt;
&lt;p&gt;Now that you&amp;rsquo;ve got all the data together, it&amp;rsquo;s time to run the extraction. Remember that extractions run faster when all of the layers are &amp;ldquo;stacked&amp;rdquo;, but that requires you to use &lt;code&gt;resample&lt;/code&gt; to get to the same origins and extents. Use &lt;code&gt;zonal&lt;/code&gt; to estimate the &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;sd&lt;/code&gt; for each of the mammalian richness, land value, and NDVI datasets. Then use &lt;code&gt;extract&lt;/code&gt; (without specifying a function) to estimate the same thig. Use &lt;code&gt;system.time()&lt;/code&gt; to bencmark each approach. I&amp;rsquo;ll demonstrate for the richness data using zonal stats.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pa.buf.vect.proj &amp;lt;- terra::project(pa.buf.vect, mammal.rich)
pa.buf.zones &amp;lt;- terra::rasterize(pa.buf.vect.proj, mam.rich.crop, field = &amp;quot;Unit_Nm&amp;quot;)
mammal.zones &amp;lt;- terra::zonal(mam.rich.crop, pa.buf.zones, fun = &amp;quot;mean&amp;quot;, na.rm=TRUE)
zonal.time &amp;lt;- system.time(terra::zonal(mam.rich.crop, pa.buf.zones, fun = &amp;quot;mean&amp;quot;, na.rm=TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;join-back-to-your-pa-dataset&#34;&gt;Join back to your PA dataset&lt;/h2&gt;
&lt;p&gt;Now that you have the raster data extracted and summarized (into the mean and standard deviation) for each buffered PA, you should be able to join it back to the dataset you created in steps 2-4. I&amp;rsquo;ll do that here&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary.df &amp;lt;- pa.income.summary %&amp;gt;% 
  left_join(., mammal.zones)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;Unit_Nm&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(summary.df)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 6 features and 3 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -1637570 ymin: 2277825 xmax: -1396163 ymax: 2675919
## Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version
## # A tibble: 6 × 4
##   Unit_Nm              meaninc                                    geometry Value
##   &amp;lt;chr&amp;gt;                  &amp;lt;dbl&amp;gt;                          &amp;lt;MULTIPOLYGON [m]&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Big Jacks Creek Wil…  50094  (((-1615346 2364480, -1615519 2363694, -16…  NA  
## 2 Bruneau-Jarbidge Ri…  50265  (((-1593547 2361288, -1593505 2361239, -15…  77.5
## 3 Cecil D. Andrus-Whi…  46314. (((-1483396 2496861, -1483426 2496828, -14…  NA  
## 4 Cecil D. Andrus-Whi…  46314. (((-1485076 2510359, -1484999 2510359, -14…  NA  
## 5 Craters of the Moon…  47762. (((-1398389 2402114, -1398445 2401816, -13…  79.9
## 6 Frank Church-River …  45915  (((-1485925 2548854, -1485887 2548829, -14…  80.3
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Building spatial databases</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/05-example/</link>
      <pubDate>Wed, 06 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/05-example/</guid>
      <description>&lt;p&gt;One of the strongest justifications for using &lt;code&gt;R&lt;/code&gt; as a Geographic Information System (GIS) is the ability to construct complete, reproducible workflows from data entry and cleaning through analysis and visualization. Constructing databases that combine spatial and tabular data is at the core of those workflows. This example should help you practice some of the key database operations that you may encounter as you conduct your own analysis.&lt;/p&gt;
&lt;h1 id=&#34;load-the-datasets-and-packages&#34;&gt;Load the datasets and packages&lt;/h1&gt;
&lt;p&gt;The data we&amp;rsquo;ll be using for today&amp;rsquo;s example and assignment are a mix of spatial and tabular data. The tabular data come from the &lt;a href=&#34;https://www.landgrabu.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Land-Grab University(LGU)&lt;/a&gt; data on parcel sales and the National Park Service&amp;rsquo;s (NPS) &lt;a href=&#34;https://irma.nps.gov/STATS/Reports/National&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;annual visitation data&lt;/a&gt; for NPS-operated units in the Intermountain and Pacific West regions. The spatial data is a shapefile from the US Protected Area Database (PADUS) and a shapefile containing the parcels described by the Land-Grab University parcel database. We&amp;rsquo;ll load each of those here and take a look at features and fields in each dataset. &lt;strong&gt;Remember that you&amp;rsquo;ll need to change the paths to match your own data.&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linking to GEOS 3.8.1, GDAL 3.2.1, PROJ 7.2.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.3     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.0     ✓ forcats 0.5.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nps.visits.csv &amp;lt;- read_csv(&#39;/Users/matthewwilliamson/Downloads/session14/ParkVisits_2020IWPW.csv&#39;, skip = 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1668 Columns: 8
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (5): ParkName, UnitCode, ParkType, Region, State
## dbl (2): Year, Month
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(nps.visits.csv)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 8
##   ParkName       UnitCode ParkType   Region   State  Year Month RecreationVisits
##   &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
## 1 Alibates Flin… ALFL     National … Intermo… TX     2020     1              273
## 2 Alibates Flin… ALFL     National … Intermo… TX     2020     2              314
## 3 Alibates Flin… ALFL     National … Intermo… TX     2020     3              233
## 4 Alibates Flin… ALFL     National … Intermo… TX     2020     4                0
## 5 Alibates Flin… ALFL     National … Intermo… TX     2020     5                0
## 6 Alibates Flin… ALFL     National … Intermo… TX     2020     6              130
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;parcels.csv &amp;lt;- read_csv(&#39;/Users/matthewwilliamson/Downloads/session14/Parcels.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 79461 Columns: 43
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (36): MTRSA_LG, Loc_State, Loc_County, LG_State, LG_Reason, University, ...
## dbl  (6): Acres, Yr_ST_Accept, Yr_Uni_Assign, Yr_Patent, Date_Patent, GIS_Ac...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(parcels.csv)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 43
##   MTRSA_LG      Loc_State Loc_County Acres LG_State LG_Reason        University 
##   &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt;      
## 1 &amp;quot;AR050020S02… AR        Garland      160 AL       Patented under … Auburn Uni…
## 2 &amp;quot;KS060210S00… KS        McPherson     40 AL       Patented under … Auburn Uni…
## 3 &amp;quot;KS060210S00… KS        McPherson     40 AL       Patented under … Auburn Uni…
## 4 &amp;quot;KS060190S01… KS        Barton        80 AL       Patented under … Auburn Uni…
## 5 &amp;quot;KS060190S01… KS        Barton        80 AL       Patented under … Auburn Uni…
## 6 &amp;quot;KS060210S00… KS        McPherson     80 AL       Patented under … Auburn Uni…
## # … with 36 more variables: Uni_Ben_History &amp;lt;chr&amp;gt;, Royce_ID &amp;lt;chr&amp;gt;,
## #   Tribal_Nation &amp;lt;chr&amp;gt;, US_Acquired_Mode &amp;lt;chr&amp;gt;, Cession_States &amp;lt;chr&amp;gt;,
## #   Royce_Link &amp;lt;chr&amp;gt;, Yr_US_Acquire &amp;lt;chr&amp;gt;, Date_US_Acquire &amp;lt;chr&amp;gt;,
## #   US_Paid_for_Parcel &amp;lt;chr&amp;gt;, Endow_Raised_Parcel &amp;lt;chr&amp;gt;,
## #   Uni_Raise_US_Pay_Multiple &amp;lt;chr&amp;gt;, Yr_ST_Accept &amp;lt;dbl&amp;gt;, Yr_Uni_Assign &amp;lt;dbl&amp;gt;,
## #   Yr_Patent &amp;lt;dbl&amp;gt;, Date_Patent &amp;lt;dbl&amp;gt;, Patentees &amp;lt;chr&amp;gt;,
## #   Patent_Source_Reason &amp;lt;chr&amp;gt;, Source_ID &amp;lt;chr&amp;gt;, Source &amp;lt;chr&amp;gt;,
## #   Source_Loc &amp;lt;chr&amp;gt;, Source_Type &amp;lt;chr&amp;gt;, Source_Form &amp;lt;chr&amp;gt;, Source_Acqu &amp;lt;chr&amp;gt;,
## #   Source_Acqu_Detail &amp;lt;chr&amp;gt;, Located_GIS &amp;lt;chr&amp;gt;, Parcel_Link &amp;lt;chr&amp;gt;,
## #   MTRSA &amp;lt;chr&amp;gt;, MTRS &amp;lt;chr&amp;gt;, A_or_L &amp;lt;chr&amp;gt;, Aliquot &amp;lt;chr&amp;gt;, Types &amp;lt;chr&amp;gt;,
## #   GISAcres &amp;lt;dbl&amp;gt;, GIS_Acre_Div_List_Acre &amp;lt;dbl&amp;gt;, Polygon &amp;lt;chr&amp;gt;,
## #   Accuracy &amp;lt;chr&amp;gt;, LG_Royce &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;regional.pas.sf &amp;lt;- read_sf(&#39;/Users/matthewwilliamson/Downloads/session14/reg_pas.shp&#39;)

regional.pas.sf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 544 features and 32 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -2034299 ymin: 1004785 xmax: -530474 ymax: 3059862
## Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version
## # A tibble: 544 × 33
##    Categry Own_Typ Own_Nam Loc_Own Mng_Typ Mang_Nm Loc_Mng Des_Tp Loc_Ds Unit_Nm
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  
##  1 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   AS     Nation…
##  2 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   CA     San Lu…
##  3 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   CA     San Lu…
##  4 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   COORD  C. J. …
##  5 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   COORD  Carey …
##  6 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   COORD  Hagerm…
##  7 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   COORD  North …
##  8 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   COORD  Sand C…
##  9 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   FR     Eagle …
## 10 Procla… DESG    DESG    &amp;lt;NA&amp;gt;    FED     FWS     0       PROC   FSA    Farm S…
## # … with 534 more rows, and 23 more variables: Loc_Nm &amp;lt;chr&amp;gt;, Stat_Nm &amp;lt;chr&amp;gt;,
## #   Agg_Src &amp;lt;chr&amp;gt;, GIS_Src &amp;lt;chr&amp;gt;, Src_Dat &amp;lt;chr&amp;gt;, GIS_Acr &amp;lt;int&amp;gt;, Sr_PAID &amp;lt;chr&amp;gt;,
## #   WDPA_Cd &amp;lt;int&amp;gt;, Pb_Accs &amp;lt;chr&amp;gt;, Accss_S &amp;lt;chr&amp;gt;, Accss_D &amp;lt;chr&amp;gt;, GAP_Sts &amp;lt;chr&amp;gt;,
## #   GAPCdSr &amp;lt;chr&amp;gt;, GAPCdDt &amp;lt;chr&amp;gt;, IUCN_Ct &amp;lt;chr&amp;gt;, IUCNCtS &amp;lt;chr&amp;gt;, IUCNCtD &amp;lt;chr&amp;gt;,
## #   Dat_Est &amp;lt;chr&amp;gt;, Commnts &amp;lt;chr&amp;gt;, SHAPE_L &amp;lt;dbl&amp;gt;, SHAPE_A &amp;lt;dbl&amp;gt;, FetClss &amp;lt;chr&amp;gt;,
## #   geometry &amp;lt;MULTIPOLYGON [m]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;regional.parcels.sf &amp;lt;- read_sf(&#39;/Users/matthewwilliamson/Downloads/session14/Parcel_Polygons.shp&#39;)

regional.parcels.sf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Simple feature collection with 79360 features and 4 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XYZ
## Bounding box:  xmin: -124.5124 ymin: 28.82222 xmax: -81.65863 ymax: 49.00015
## z_range:       zmin: 0 zmax: 0
## Geodetic CRS:  NAD83
## # A tibble: 79,360 × 5
##    OBJECTID_1 MTRSA_LG    Shape_Leng Shape_Area                         geometry
##         &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;               &amp;lt;MULTIPOLYGON [°]&amp;gt;
##  1          1 AR050020N0…     0.0317  0.0000626 Z (((-92.66263 34.76826 0, -92.…
##  2          2 AR050020S0…     0.0325  0.0000651 Z (((-93.26224 34.55195 0, -93.…
##  3          3 AR050020S0…     0.0321  0.0000639 Z (((-93.29927 34.53098 0, -93.…
##  4          4 AR050030N0…     0.0308  0.0000580 Z (((-93.66021 34.93445 0, -93.…
##  5          5 AR050030S0…     0.0324  0.0000652 Z (((-93.27249 34.44986 0, -93.…
##  6          6 AR050050N0…     0.0164  0.0000166 Z (((-94.33553 35.10705 0, -94.…
##  7          7 AR050050N0…     0.0163  0.0000164 Z (((-94.33586 35.0962 0, -94.3…
##  8          8 AR050050N0…     0.0235  0.0000328 Z (((-94.33575 35.0998 0, -94.3…
##  9          9 AR050060S0…     0.0324  0.0000651 Z (((-93.33463 34.21174 0, -93.…
## 10         10 AR050060S0…     0.0323  0.0000643 Z (((-93.768 34.2144 0, -93.767…
## # … with 79,350 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;check-the-geometries-understand-the-data&#34;&gt;Check the geometries, understand the data&lt;/h1&gt;
&lt;p&gt;By now you know that before we get too far down the road, we want to check the geometries and projections of our spatial data. Let&amp;rsquo;s do that here. We can use the &lt;code&gt;all()&lt;/code&gt; function to check to see if all of the geometries are valid (i.e., &lt;code&gt;st_is_valid()&lt;/code&gt; returns all &lt;code&gt;TRUE&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;all(st_is_valid(regional.pas.sf))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;all(st_is_valid(regional.parcels.sf))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## st_as_s2(): dropping Z and/or M coordinate
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, they aren&amp;rsquo;t all valid so we&amp;rsquo;ll need to fix that here.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;regional.pas.valid &amp;lt;- st_make_valid(regional.pas.sf)
all(st_is_valid(regional.pas.valid)) #fixed it!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;regional.parcels.valid &amp;lt;- st_make_valid(regional.parcels.sf)
all(st_is_valid(regional.parcels.valid)) #fixed it!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we&amp;rsquo;ve gotten the geometries cleaned up, we need to make sure the two datasets align.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(regional.parcels.valid) == st_crs(regional.pas.valid) #Of course they dont
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;parcels.project &amp;lt;- regional.parcels.valid %&amp;gt;% 
  st_transform(., crs = st_crs(regional.pas.valid))

st_crs(parcels.project) == st_crs(regional.pas.valid) #fixed it!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;where-are-we-going&#34;&gt;Where are we going?&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;d like to explore how visitation to a number of NPS units contrasts with the amount of money the US paid to purchase the land those units sit on. This means we&amp;rsquo;ll need a dataset that contains: a) the total number of visits to each unit in 2020, b) the number of parcels that were sold within the present-day boundaries of those units, and c) the sum of the value paid for those units.&lt;/p&gt;
&lt;h1 id=&#34;subset-the-data-to-suit-our-questions&#34;&gt;Subset the data to suit our questions&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;m going to focus on Idaho for this example, so I&amp;rsquo;ll subset the data for that here.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.parcels.csv &amp;lt;- parcels.csv %&amp;gt;% 
  filter(., Loc_State == &amp;quot;ID&amp;quot;)

id.park.visits &amp;lt;- nps.visits.csv %&amp;gt;% 
  filter(., State == &amp;quot;ID&amp;quot;)

id.pas.sf &amp;lt;- regional.pas.valid %&amp;gt;% 
  filter(., Stat_Nm == &amp;quot;ID&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;joining-with-keypairs&#34;&gt;Joining with keypairs&lt;/h1&gt;
&lt;p&gt;You&amp;rsquo;ll notice that the the LGU parcels dataset does not have many attributes and none that will let us use &lt;code&gt;filter&lt;/code&gt; to reduce the dataset. That&amp;rsquo;s because the bulk of the tabular data is stored in the &lt;code&gt;parcels.csv&lt;/code&gt; file. We&amp;rsquo;ll have to join them before we can subset them based on an attribute. Remember, that the &lt;code&gt;_join&lt;/code&gt; commands return objects with the &lt;code&gt;class&lt;/code&gt; of the first argument.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;join1 &amp;lt;- left_join(id.parcels.csv, parcels.project, by = &amp;quot;MTRSA_LG&amp;quot;)
class(join1)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spec_tbl_df&amp;quot; &amp;quot;tbl_df&amp;quot;      &amp;quot;tbl&amp;quot;         &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;join2 &amp;lt;- left_join(parcels.project, id.parcels.csv, by = &amp;quot;MTRSA_LG&amp;quot;)
class(join2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;sf&amp;quot;         &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given this, there are two ways we might approach joining and subsetting the data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.parcels.sf &amp;lt;- left_join(parcels.project, id.parcels.csv, by = &amp;quot;MTRSA_LG&amp;quot;) %&amp;gt;% 
  filter(., Loc_State == &amp;quot;ID&amp;quot;)
class(id.parcels.sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;sf&amp;quot;         &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nrow(id.parcels.sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 336
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.parcels.sf2 &amp;lt;- inner_join(parcels.project, id.parcels.csv, by = &amp;quot;MTRSA_LG&amp;quot;)
class(id.parcels.sf2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;sf&amp;quot;         &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nrow(id.parcels.sf2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 336
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Okay, now all we need to do is get the visit data attached to the NPS. But before we can do that, we need to summarize the monthly visits into a total for the year.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.park.visits.ann &amp;lt;- id.park.visits %&amp;gt;% 
  group_by(UnitCode) %&amp;gt;% 
  summarise(., Total = sum(RecreationVisits))

id.pas.visits &amp;lt;- id.pas.sf %&amp;gt;% 
  inner_join(., id.park.visits.ann, by = c(&amp;quot;Loc_Nm&amp;quot; = &amp;quot;UnitCode&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;joining-based-on-location&#34;&gt;Joining based on location&lt;/h1&gt;
&lt;p&gt;Now we need to figure out how many parcels are within the orignal NPS unit boundaries. We&amp;rsquo;ll use a spatial join (&lt;code&gt;st_join&lt;/code&gt;) to make that happen. Remember, that we can use any of the binary predicates (&lt;code&gt;?geos_binary_pred&lt;/code&gt;) to specify how we&amp;rsquo;d like to join the data. Here, I&amp;rsquo;ll &lt;code&gt;st_is_within_distance&lt;/code&gt; to illustrate.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;parcels.in.pas &amp;lt;- st_join(id.pas.visits, id.parcels.sf, join=st_is_within_distance, dist=100000)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;estimating-the-total-amount-paid&#34;&gt;Estimating the total amount paid&lt;/h1&gt;
&lt;p&gt;The result of selecting all of the parcels with 100000m of the NPS units is a data frame with 26 features (i.e., 26 parcels met the criteria). Now we need to calculate the total value (remember that we have to fix the currency to make it numeric).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;parcels.in.pas.sum &amp;lt;- parcels.in.pas %&amp;gt;% 
  group_by(Unit_Nm) %&amp;gt;% 
  summarise(., total = sum(readr::parse_number(US_Paid_for_Parcel), na.rm=TRUE))
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Working with rasters in R</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/04-example/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/04-example/</guid>
      <description>&lt;p&gt;As we have discussed (constantly), we need to get all of our data aligned before we can do much with spatial analysis or plotting. Workflows for rasters are basically the same as those for vectors (i.e., read the data, compare CRSs, reproject if necessary). The main difference is that rasters introduce a few additional components that we need to match up - the orgin, extent, and resolution. We&amp;rsquo;ll start by looking at how we can verify if/when things are aligned and then move to &amp;lsquo;fixing&amp;rsquo; issues of non-alignment.&lt;/p&gt;
&lt;h1 id=&#34;read-the-data&#34;&gt;Read the data&lt;/h1&gt;
&lt;p&gt;We use the &lt;code&gt;rast()&lt;/code&gt; function from the &lt;code&gt;terra&lt;/code&gt; package to read the data into our workspace. Note that the pathnames here are not the same as what you&amp;rsquo;ll use for the lab (because these paths correspond to my computer).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hm &amp;lt;- rast(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session08/hmi.tif&#39;)

val &amp;lt;- rast(&#39;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session08/idval.tif&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;check-the-projection&#34;&gt;Check the projection&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at the data. We notice a few obvious differences right off the bat.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/04-example_files/figure-html/initplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The plots make it pretty obvious that our extents are different, but what else might be different? Let&amp;rsquo;s use the &lt;code&gt;terra::crs&lt;/code&gt; command to check on the different Coordinate Reference Systems.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;crs(val) == crs(hm)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;crs(hm, proj=TRUE) #use the proj argument to make the output a bit more readable (but deprecated)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;crs(val, proj=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;reproject-and-crop-the-raster&#34;&gt;Reproject and crop the raster&lt;/h1&gt;
&lt;p&gt;As we have discussed, projecting rasters is a bit tricky because we can distort the cells and potentially alter the attribute-geometry-relationship. That said, we often don&amp;rsquo;t want to deal with giant rasters when we are only analyzing a small area. Cropping can help us reduce the size of the rasters, but will require us to reproject one of the rasters to get there. Let&amp;rsquo;s reproject the smaller raster (because it&amp;rsquo;s faster) and then crop the large raster.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;val.proj &amp;lt;- project(val, crs(hm))
hm.crop &amp;lt;- crop(hm, val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/04-example_files/figure-html/cropplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is looking better, does this mean we have the two rasters aligned?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;crs(hm.crop) == crs(val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like something else might still be off. Let&amp;rsquo;s check the resolution, origin, and extent.&lt;/p&gt;
&lt;h1 id=&#34;resampling-aggregating-disaggregating&#34;&gt;Resampling, aggregating, disaggregating&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res(hm.crop) == res(val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ext(hm.crop) == ext(val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;origin(hm.crop) == origin(val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the two rasters have different resolutions, extents, and origins. Although, we reprojected the data into the proper projection, this doesn&amp;rsquo;t change these other fundamental properties of the data. We&amp;rsquo;ll use &lt;code&gt;resample()&lt;/code&gt; here to fix this because we need to both change the resolution and the location of the cell centers (if we were just changing resolutions, we could use &lt;code&gt;aggregate()&lt;/code&gt;, or &lt;code&gt;disaggregate()&lt;/code&gt;). We&amp;rsquo;ll resample to the coarser resolution, but we could go the other way if it made sense for the data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res(hm.crop)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 270 270
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res(val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 480 480
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hm.rsmple &amp;lt;- resample(hm.crop, val.proj, method=&#39;bilinear&#39;)
crs(hm.rsmple) == crs(val.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;running-functions-on-multi-layer-rasters&#34;&gt;Running functions on multi-layer rasters&lt;/h1&gt;
&lt;p&gt;Great, we&amp;rsquo;ve gotten our data aligned. Let&amp;rsquo;s make a single &lt;code&gt;SpatRast&lt;/code&gt; object with 2 layers so that we can run some smoothing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;combined.data &amp;lt;- rast(list(hm.rsmple, val.proj))
nlyr(combined.data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(combined.data)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/04-example_files/figure-html/rstcombine-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One of the nice parts about multilayer rasters is that we can run functions across all pixels in all the layers of a multilayer raster with relative ease. One place we might use this is to scale and center our data before a regression analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;combined.scale &amp;lt;- scale(combined.data)
plot(combined.scale)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/04-example_files/figure-html/focl-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;repetitive-operations&#34;&gt;Repetitive operations&lt;/h1&gt;
&lt;p&gt;One of the things you&amp;rsquo;ll notice is that you end up doing a lot of copy-and-pasting when you&amp;rsquo;re processing lots of rasters. This can lead to errors that can be really difficult to diagnose. One way around this is to build functions that take &amp;lsquo;anonymous&amp;rsquo; arguments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working with vectors in R</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/03-example/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/03-example/</guid>
      <description>&lt;p&gt;Today we&amp;rsquo;ll build on the introductory discussion we were having about vector operations and the &lt;code&gt;sf&lt;/code&gt; package. We&amp;rsquo;ll build a few vectors from scratch and then move on to explore a broader suite of common vector operations implemented by the &lt;code&gt;sf&lt;/code&gt; package.&lt;/p&gt;
&lt;h2 id=&#34;a-reminder-about-vector-geometries-in-r&#34;&gt;A reminder about vector geometries in &lt;code&gt;R&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;You&amp;rsquo;ll recall that the &lt;code&gt;sf&lt;/code&gt; package organizes the different types of vectors (e.g., points, lines, polygons) in to a hierarchical structure organized by complexity of geometries contained within an &lt;code&gt;R&lt;/code&gt; object. For example, a single point will be a &lt;code&gt;POINT&lt;/code&gt;, several points will be a &lt;code&gt;MULTIPOINT&lt;/code&gt;, and an object containing points, polygons, and lines will be a &lt;code&gt;GEOMETRYCOLLECTION&lt;/code&gt;. We need to be aware of what types of geometries and objects we have becasue some operations are restricted to particular types of objects or geometries as indicated by errors that read:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Error in UseMethod(&amp;quot;st_crs&amp;lt;-&amp;quot;) :  no applicable method for &#39;st_crs&amp;lt;-&#39; applied to an object of class &amp;quot;c(&#39;XY&#39;, &#39;POINT&#39;, &#39;sfg&#39;)&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which indicates that the function (&lt;code&gt;st_crs&lt;/code&gt;) does not have a method defined for the type of object it&amp;rsquo;s being applied to. Note that the function inside &lt;code&gt;UseMethod&lt;/code&gt; will be replaced by whichever function you&amp;rsquo;re attempting to apply to your object and the &lt;code&gt;object of class&lt;/code&gt; component will vary based on the function and the object class.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;POINT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;single point geometry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MULTIPOINT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;set of points&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;LINESTRING&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;single linestring (two or more points connected by straight lines)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MULTILINESTRING&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;set of linestrings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;POLYGON&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;exterior ring with zero or more inner rings, denoting holes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MULTIPOLYGON&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;set of polygons&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GEOMETRYCOLLECTION&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;set of the geometries above&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As is, these geometries are built on vertices with coordinates that are based on the Cartesian plane and thus are &amp;ldquo;spatial&amp;rdquo;, but not georeferenced or geographic. In order to convert these &lt;code&gt;sf&lt;/code&gt; geometries to a geogrphic object (i.e., one with a CRS and whose location depicts and actual spot on the earth&amp;rsquo;s surface), we use &lt;code&gt;st_sfc()&lt;/code&gt; to create a simple feature geography list column (see &lt;code&gt;?st_sfc&lt;/code&gt; for an example of this workflow).&lt;/p&gt;
&lt;h2 id=&#34;conventions-in-sf-and-the-tidyverse&#34;&gt;Conventions in &lt;code&gt;sf&lt;/code&gt; and the &lt;code&gt;tidyverse&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;One of the benefits of the &lt;code&gt;sf&lt;/code&gt; package is that it is designed to interface with the &lt;a href=&#34;https://www.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;tidyverse&lt;/code&gt;&lt;/a&gt; suite of packages. One of the appealing parts of working with &lt;code&gt;tidyverse&lt;/code&gt; packages is that they share an underlying philosophy, data structure, and grammar. This can make life a lot easier as you move from getting your data into &lt;code&gt;R&lt;/code&gt;, constructing a set of covariates (including those derived from spatial data), analyzing, and plotting (or mapping) those data. People have strong opinions about the &lt;code&gt;tidyverse&lt;/code&gt;, but I find it to be an (eventually) useful way for people to gain some intuition for working in &lt;code&gt;R&lt;/code&gt;. One of the grammatical conventions used in the &lt;code&gt;tidyverse&lt;/code&gt; suite of packages is the use &lt;code&gt;_&lt;/code&gt; in function calls (this is known as snake case should you ever need to know that at a dinner party). The &lt;code&gt;_&lt;/code&gt; is typically used to separate the verb in a function call from its predicate. For example, &lt;code&gt;bind_rows()&lt;/code&gt; in the &lt;code&gt;dplyr&lt;/code&gt; package &amp;ldquo;binds&amp;rdquo; (the verb) rows (the predicate) wheras &lt;code&gt;bind_cols()&lt;/code&gt; binds columns. For the &lt;code&gt;sf&lt;/code&gt; package it&amp;rsquo;s slightly different in that most of the functions begin with a &lt;code&gt;st_&lt;/code&gt; or &lt;code&gt;sf_&lt;/code&gt; prefix to indicate that the function is designed to work on spatial objects followed by a word (or words) describing what the operation does (e.g., &lt;code&gt;st_centroid()&lt;/code&gt; returns a &lt;code&gt;MULTIPOINT&lt;/code&gt; object with each point located at the centroid of a polygon). We can classify these functions based on what they are expected to return:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Predicates&lt;/strong&gt;: evaluate a logical statement asserting that a property is &lt;code&gt;TRUE&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Measures&lt;/strong&gt;: return a numeric value with units based on the units of the CRS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transformations&lt;/strong&gt;: create new geometries based on input geometries.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can also distinguish these functions based on how many geometries that operate on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unary&lt;/strong&gt;: operate on a single geometry at a time (meaning that if you have a &lt;code&gt;MULTI*&lt;/code&gt; object the function works on each geometry individually)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Binary&lt;/strong&gt;: operate on pairs of geometries&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;n-ary&lt;/strong&gt;: operate on sets of geometries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We&amp;rsquo;ll focus on the unary operators for now, but the binary and n-ary operators will become more important as we move to develop databases for spatial analysis.&lt;/p&gt;
&lt;h3 id=&#34;unary-predicates&#34;&gt;Unary predicates&lt;/h3&gt;
&lt;p&gt;Unary predicates are helpful &amp;lsquo;checks&amp;rsquo; to make sure the object you are working with has the properties you might expect. Are the geometries valid? Is the data projected? Because we are asking a set of &lt;code&gt;TRUE/FALSE&lt;/code&gt; questions, these functions are specified as &lt;code&gt;st_is_&lt;/code&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;predicate&lt;/th&gt;
&lt;th&gt;asks&amp;hellip;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;simple&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;is the geometry self-intersecting (i.e., simple)?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;valid&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;is the geometry valid?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;empty&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;is the geometry column of an object empty?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;longlat&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;does the object have geographic coordinates? (&lt;code&gt;FALSE&lt;/code&gt; if coords are projected, &lt;code&gt;NA&lt;/code&gt; if no &lt;code&gt;crs&lt;/code&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;is(geometry, class)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;is the geometry of a particular class?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nc &amp;lt;- st_read(system.file(&amp;quot;shape/nc.shp&amp;quot;, package=&amp;quot;sf&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `nc&#39; from data source 
##   `/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sf/shape/nc.shp&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 100 features and 14 fields
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965
## Geodetic CRS:  NAD27
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_is_longlat(nc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_is_valid(nc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [76] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [91] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;unary-measures&#34;&gt;Unary measures&lt;/h3&gt;
&lt;p&gt;Measures return a quantity that describes the geometry&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;measure&lt;/th&gt;
&lt;th&gt;returns&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;dimension&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;0 for points, 1 for linear, 2 for polygons, possibly &lt;code&gt;NA&lt;/code&gt; for empty geometries&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;area&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;the area of a geometry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;length&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;the length of a linear geometry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;code&gt;distance&lt;/code&gt; is a binary measure that returns the distance between pairs of geometries either within a single object or between features in multiple objects&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(st_area(nc))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m^2]
## [1] 1137107793  610916077 1423145355  694378925 1520366979  967504822
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_distance(nc)[1:5,1:5]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Units: [m]
##          [,1]     [,2]     [,3]      [,4]      [,5]
## [1,]      0.0      0.0  25591.8 439493.26 299049.94
## [2,]      0.0      0.0      0.0 408416.68 268284.09
## [3,]  25591.8      0.0      0.0 366648.94 226461.23
## [4,] 439493.3 408416.7 366648.9      0.00  67066.43
## [5,] 299049.9 268284.1 226461.2  67066.43      0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;unary-transformers&#34;&gt;Unary transformers&lt;/h3&gt;
&lt;p&gt;Unary transformations work on a per object basis and return a new geometry for each geometry.
These are a few of the most common, we&amp;rsquo;ll encounter a few more as the semester continues.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;transformer&lt;/th&gt;
&lt;th&gt;returns a geometry &amp;hellip;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;centroid&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;of type &lt;code&gt;POINT&lt;/code&gt; with the geometry&amp;rsquo;s centroid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;buffer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;that is this larger (or smaller) than the input geometry, depending on the buffer size&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;jitter&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;that was moved in space a certain amount, using a bivariate uniform distribution&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;boundary&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;with the boundary of the input geometry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;convex_hull&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;that forms the convex hull of the input geometry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;line_merge&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;after merging connecting &lt;code&gt;LINESTRING&lt;/code&gt; elements of a &lt;code&gt;MULTILINESTRING&lt;/code&gt; into longer &lt;code&gt;LINESTRING&lt;/code&gt;s.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;make_valid&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;that is valid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;node&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;with added nodes to linear geometries at intersections without a node; only works on individual linear geometries&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;point_on_surface&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;with a (arbitrary) point on a surface&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;polygonize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;of type polygon, created from lines that form a closed ring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;segmentize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;a (linear) geometry with nodes at a given density or minimal distance&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;simplify&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;simplified by removing vertices/nodes (lines or polygons)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;split&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;that has been split with a splitting linestring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;transformed or convert to a new coordinate reference system (&lt;a href=&#34;http://isdrfall21.classes.spaseslab.com/example/02-example&#34;&gt;last week&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;collection_extract&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;with subgeometries from a &lt;code&gt;GEOMETRYCOLLECTION&lt;/code&gt; of a particular type&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cast&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;that is converted to another type&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(st_geometry(nc))
plot(st_geometry(st_centroid(nc)), add=TRUE, col=&#39;red&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in st_centroid.sf(nc): st_centroid assumes attributes are constant over
## geometries of x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/03-example_files/figure-html/polycent-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;using-sf-and-the-tidyverse&#34;&gt;Using &lt;code&gt;sf&lt;/code&gt; and the &lt;code&gt;tidyverse&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;As I mentioned, one of the benefits of using the &lt;code&gt;sf&lt;/code&gt; package is that commands from the other &lt;code&gt;tidyverse&lt;/code&gt; package have defined methods for spatial objects. The &lt;code&gt;dplyr&lt;/code&gt; package has a ton of helpful functions for maniputlating data in &lt;code&gt;R&lt;/code&gt;. For example, we might select a single row from a shapefile based on the value of its attributes by using the &lt;code&gt;dplyr::filter()&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;durham.cty &amp;lt;- nc %&amp;gt;% 
  filter(., NAME == &amp;quot;Durham&amp;quot;)
## We can also use the bracket approach
durham.cty2 &amp;lt;- nc[nc$NAME == &amp;quot;Durham&amp;quot;,]

plot(st_geometry(nc))
plot(st_geometry(durham.cty), add=TRUE, col=&amp;quot;blue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/03-example_files/figure-html/sffilter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Or perhaps we only want a few of the columns in the dataset (because shapefiles always have lots of extra stuff). We can use &lt;code&gt;dplyr::select()&lt;/code&gt; to choose columns by name:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nc.select &amp;lt;- nc %&amp;gt;% 
  select(., c(&amp;quot;CNTY_ID&amp;quot;, &amp;quot;NAME&amp;quot;, &amp;quot;FIPS&amp;quot;))
plot(nc.select)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/03-example_files/figure-html/sfselect-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notice that the geometries are &lt;em&gt;sticky&lt;/em&gt;, this will be important later&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Workflows for getting spatial data into R</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/02-example/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/02-example/</guid>
      <description>&lt;p&gt;Today&amp;rsquo;s exercise and assignment will focus on getting different types of spatial data into R; exploring the CRS, extent, and resolution of those objects; and aligning objects with different projections. We&amp;rsquo;ll look at ways to do this using the &lt;code&gt;sf&lt;/code&gt;, &lt;code&gt;sp&lt;/code&gt; (with &lt;code&gt;rgdal&lt;/code&gt;), &lt;code&gt;raster&lt;/code&gt;, and &lt;code&gt;terra&lt;/code&gt; packages.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting started&lt;/h2&gt;
&lt;p&gt;Remember that we&amp;rsquo;ll be using GitHub classroom so you&amp;rsquo;ll need to introduce yourself to git and then clone the Assignment 2 repository. The instructions are in &lt;a href=&#34;http://isdrfall21.classes.spaseslab.com/example/01-example/&#34;&gt;Example 1&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;loading-the-data&#34;&gt;Loading the data&lt;/h2&gt;
&lt;p&gt;I created a few small shapefiles to help illustrate the basic workflow for bringing in both shapefiles and rasters. In the code below, you&amp;rsquo;ll need to change the &lt;code&gt;filepath&lt;/code&gt; object to match the path to our shared direction. This is not an ideal practice as it makes it challenging for others to automatically reproduce your analaysis, but I&amp;rsquo;m using here because GitHub can&amp;rsquo;t handle large files like rasters or shapefiles and transferring files is more than I want to take on today&amp;hellip;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll demonstrate loading the data using &lt;code&gt;rgdal&lt;/code&gt;, &lt;code&gt;sp&lt;/code&gt;, and &lt;code&gt;sf&lt;/code&gt; packages (for shapefiles) and the &lt;code&gt;raster&lt;/code&gt; and &lt;code&gt;terra&lt;/code&gt; packages (for rasters).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#load the necessary libraries
library(sp)
library(sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linking to GEOS 3.9.1, GDAL 3.2.2, PROJ 7.2.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rgdal)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## rgdal: version: 1.5-23, (SVN revision 1121)
## Geospatial Data Abstraction Library extensions to R successfully loaded
## Loaded GDAL runtime: GDAL 3.1.4, released 2020/10/20
## Path to GDAL shared files: /Library/Frameworks/R.framework/Versions/4.0/Resources/library/rgdal/gdal
## GDAL binary built with GEOS: TRUE 
## Loaded PROJ runtime: Rel. 6.3.1, February 10th, 2020, [PJ_VERSION: 631]
## Path to PROJ shared files: /Library/Frameworks/R.framework/Versions/4.0/Resources/library/rgdal/proj
## Linking to sp version:1.4-5
## To mute warnings of possible GDAL/OSR exportToProj4() degradation,
## use options(&amp;quot;rgdal_show_exportToProj4_warnings&amp;quot;=&amp;quot;none&amp;quot;) before loading rgdal.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(raster)
library(terra)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## terra version 1.2.11
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;terra&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:rgdal&#39;:
## 
##     project
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;filepath &amp;lt;- &amp;quot;/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session04/&amp;quot;

#shapefiles
id.sp &amp;lt;- readOGR(paste0(filepath, &amp;quot;ID.shp&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## OGR data source with driver: ESRI Shapefile 
## Source: &amp;quot;/Volumes/GoogleDrive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session04/ID.shp&amp;quot;, layer: &amp;quot;ID&amp;quot;
## with 1 features
## It has 14 fields
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.sf &amp;lt;- st_read(paste0(filepath, &amp;quot;ID.shp&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `ID&#39; from data source 
##   `/Volumes/GoogleDrive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/session04/ID.shp&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 1 feature and 14 fields
## Geometry type: POLYGON
## Dimension:     XY
## Bounding box:  xmin: -117.243 ymin: 41.98818 xmax: -111.0435 ymax: 49.00085
## Geodetic CRS:  NAD83
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#rasters
id.raster &amp;lt;- raster(paste0(filepath, &amp;quot;idval.tif&amp;quot;))
id.rast &amp;lt;-  rast(paste0(filepath, &amp;quot;idval.tif&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;check-the-geometry&#34;&gt;Check the geometry&lt;/h2&gt;
&lt;p&gt;Polygon data is often developed by hand using a technique called &amp;lsquo;heads-up digitizing&amp;rsquo;. This can lead to some subtle, but important errors in the geometry that eventually create problems for us down the road. We can check that using &lt;code&gt;st_is_vald()&lt;/code&gt; and if that returns &lt;code&gt;FALSE&lt;/code&gt; we can use &lt;code&gt;st_make_valid()&lt;/code&gt; to fix it (hopefully).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_is_valid(id.sf)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#luckily it&#39;s true so we don&#39;t need st_make_valid() here
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we&amp;rsquo;ve got the data into &lt;code&gt;R&lt;/code&gt;, we probably want to take a look at it. We can do that quickly just using the base &lt;code&gt;plot&lt;/code&gt; function (we&amp;rsquo;ll use fancier methods later).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(id.raster)
plot(id.sp, add=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/02-example_files/figure-html/initplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(id.rast)
plot(st_geometry(id.sf), add=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/02-example_files/figure-html/initplot-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What do you notice? The Idaho shapefile doesn&amp;rsquo;t show up!! Leading us to our next step:&lt;/p&gt;
&lt;h2 id=&#34;check-the-projections&#34;&gt;Check the projections&lt;/h2&gt;
&lt;p&gt;As we discussed in class, we can&amp;rsquo;t really do much with spatial data in R until we get all the pieces aligned. The plot suggests the data aren&amp;rsquo;t in the same projection, but we can check that more formally, here. Notice the use of &lt;code&gt;as&lt;/code&gt; to coerce the &lt;code&gt;sf&lt;/code&gt; object into a &lt;code&gt;Spatial*&lt;/code&gt; object. This is necessary in a number of places because certain operations are only defined for a subset of &lt;code&gt;R&lt;/code&gt; objects.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;proj4string(id.sp) == proj4string(id.raster)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in proj4string(id.sp): CRS object has comment, which is lost in output
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(id.sf) == st_crs(id.raster)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;identicalCRS(id.sp, id.raster)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;identicalCRS(as(id.sf, &amp;quot;Spatial&amp;quot;), id.raster)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reproject-the-data&#34;&gt;Reproject the data&lt;/h2&gt;
&lt;p&gt;As the tests above indicate, our data are not in the same projection. We need to reproject them!! Here are a few ways to do it. Notice that I demonstrate how to project the rasters to the shapefile projection - I generally don&amp;rsquo;t recommend this, but am showing it here for completeness.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;new.crs &amp;lt;- CRS(&amp;quot;+init=epsg:2163&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in showSRID(uprojargs, format = &amp;quot;PROJ&amp;quot;, multiline = &amp;quot;NO&amp;quot;, prefer_proj =
## prefer_proj): Discarded datum unknown in Proj4 definition
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id.sf.proj &amp;lt;- id.sf %&amp;gt;% st_transform(., new.crs)
id.sp.proj &amp;lt;- spTransform(id.sp, new.crs)

id.raster.proj &amp;lt;- projectRaster(id.raster, res = 480, crs=new.crs)
id.rast.proj &amp;lt;- terra::project(id.rast, as(id.raster.proj, &amp;quot;SpatRaster&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;lets-see-if-that-worked&#34;&gt;Let&amp;rsquo;s see if that worked&lt;/h2&gt;
&lt;p&gt;Always good to double-check&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;proj4string(id.sp.proj) == proj4string(id.raster.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in proj4string(id.sp.proj): CRS object has comment, which is lost in
## output
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;st_crs(id.sf.proj) == st_crs(id.raster.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;identicalCRS(id.sp.proj, id.raster.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;identicalCRS(as(id.sf.proj, &amp;quot;Spatial&amp;quot;), id.raster.proj)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;plot-it-again&#34;&gt;Plot it again&lt;/h2&gt;
&lt;p&gt;Now it looks like everything is lined up, we should be able to generate a quick plot to look at that data&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(id.raster.proj)
plot(id.sp.proj, add=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/02-example_files/figure-html/plotit2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Or using the &lt;code&gt;sf&lt;/code&gt; &lt;code&gt;st_geometry&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(id.rast.proj)
plot(st_geometry(id.sf.proj), add=TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/02-example_files/figure-html/plotit3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to course resources, Rmarkdown, and data in R</title>
      <link>http://isdrfall21.classes.spaseslab.com/example/01-example/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      <guid>http://isdrfall21.classes.spaseslab.com/example/01-example/</guid>
      <description>&lt;h2 id=&#34;lets-git-started&#34;&gt;Let&amp;rsquo;s &amp;ldquo;git&amp;rdquo; started&lt;/h2&gt;
&lt;p&gt;We are using GitHub classroom for all of the assignments in this course. This allows each of you to have your own repositories for version control and backup of your code without the worries of stepping on someone else toes. The goal of this class is not to have you become a &amp;lsquo;master&amp;rsquo; of all things git, but I am hoping you&amp;rsquo;ll learn the utility of version control and adopt as much of it as make sense for you and your workflows.&lt;/p&gt;
&lt;h3 id=&#34;accept-the-invitation-to-the-assignment-repo&#34;&gt;Accept the invitation to the assignment repo&lt;/h3&gt;
&lt;p&gt;The first thing you&amp;rsquo;ll need to do is accept the invitation to &amp;lsquo;assignment-1` repository (repo). This &lt;em&gt;should&lt;/em&gt; automatically clone (make an exact copy) of the assignment repo in your personal account.&lt;/p&gt;
&lt;h3 id=&#34;making-sure-rstudio-server-can-access-your-github-account&#34;&gt;Making sure Rstudio server can access your GitHub account&lt;/h3&gt;
&lt;p&gt;Unfortunately, GitHub has ended its support for username/password remote authentication. Instead, it uses something called a Personal Access Token. You can read more about it &lt;a href=&#34;https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; if you are interested, but the easiest way to deal with this is by following Jenny Bryan&amp;rsquo;s &lt;a href=&#34;https://happygitwithr.com/credential-caching.html#credential-caching&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;happygitwithr&lt;/a&gt; recommended approach:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Introduce yourself to git:
There are a number of ways to do this, but I find this to be the easiest&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(usethis) #you may need to install this using install.packages(&#39;usethis&#39;)
use_git_config(user.name = &amp;quot;Jane Doe&amp;quot;, user.email = &amp;quot;jane@example.org&amp;quot;) #your info here
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Get a PAT if you don&amp;rsquo;t have one already (make sure you save it somewhere)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;usethis::create_github_token()
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Store your credential for use in RStudio&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(gitcreds) #may need to install this too

gitcreds_set() #should prompt you for your pat - paste it here
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Verify that Rstudio has saved your credential&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gitcreds_get()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R should return something that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/img/01/credentialsuccess.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;bring-the-project-into-rstudio&#34;&gt;Bring the project into RStudio&lt;/h3&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Go to File&amp;gt;New Project and choose the &amp;ldquo;Version Control&amp;rdquo; option&lt;/li&gt;
&lt;li&gt;Select &amp;ldquo;Git&amp;rdquo; (Not Subversion)&lt;/li&gt;
&lt;li&gt;paste the link from the &amp;ldquo;Clone Repository&amp;rdquo; button into the &amp;ldquo;Repository URL&amp;rdquo; space&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;verify-that-the-git-tab-is-available-and-that-your-project-is-shown-in-the-upper-right-hand-corner&#34;&gt;Verify that the &amp;ldquo;Git&amp;rdquo; tab is available and that your project is shown in the upper right-hand corner&lt;/h3&gt;
&lt;p&gt;Assuming all this has worked, you should be able to click on the &amp;ldquo;Git&amp;rdquo; tab and see something like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/img/01/gittab.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;basic-workflow&#34;&gt;Basic workflow&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Everytime you begin working on code, make sure you &amp;ldquo;Pull&amp;rdquo; from the remote repository to make sure you have the most recent version of things (this is especially important when you are collaborating with people).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make some changes to code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Save those changes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;Commit&amp;rdquo; those changes - Think of commits as &amp;lsquo;breadcrumbs&amp;rsquo; they help you remember where you were in the coding process in case you need to revert back to a previous version. Your commit messages should help you remember what was &amp;lsquo;happening&amp;rsquo; in the code when you made the commit. In general, you should save and commit fairly frequently and especially everytime you do something &amp;lsquo;consequential&amp;rsquo;. Git allows you to &amp;lsquo;turn back time&amp;rsquo;, but that&amp;rsquo;s only useful if you left enough information to get back to where you want to be.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Push your work to the remote - when you&amp;rsquo;re done working on the project for the day, push your local changes to the remote. This will ensure that if you switch computers or if someone else is going to work on the project, you (or they) will have the most recent version. Plus, if you don&amp;rsquo;t do this, step 1 will really mess you up.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;r-markdown&#34;&gt;R Markdown&lt;/h2&gt;
&lt;p&gt;This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;a href=&#34;http://rmarkdown.rstudio.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://rmarkdown.rstudio.com&lt;/a&gt;. We&amp;rsquo;ll be using Rmarkdown for the assignments in class and this website was built (generally) using Rmarkdown. You can create new Rmarkdown documents by going to File &amp;raquo; New File &amp;raquo; New Rmarkdown (we&amp;rsquo;ll be using html for this class)&lt;/p&gt;
&lt;p&gt;When you click the &lt;strong&gt;Knit&lt;/strong&gt; button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.&lt;/p&gt;
&lt;p&gt;There are lots of helpful resources to help you get started using Rmarkdown. There&amp;rsquo;s a &lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cheatsheet&lt;/a&gt; and a much longer &lt;a href=&#34;https://bookdown.org/yihui/rmarkdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;user&amp;rsquo;s guide&lt;/a&gt;. I don&amp;rsquo;t expect you to become an expert in Rmarkdown, but it is a helpful way to keep all of your thougths and code together in a single, coherent document. Getting proficient in Rmarkdown and git allows you to work with collaborators on an analysis, graphics, and manuscript all within a single platform. This fully-integrated workflow takes practice and patience (especially when you have collaborators that are new to this approach), this course is just an initial step down that path. I&amp;rsquo;ll do my best to keep it simple - please let me know if you have questions!&lt;/p&gt;
&lt;p&gt;You can embed an R code chunk like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(cars)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;including-plots&#34;&gt;Including Plots&lt;/h3&gt;
&lt;p&gt;You can also embed plots, for example:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://isdrfall21.classes.spaseslab.com/example/01-example_files/figure-html/pressure-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that the &lt;code&gt;echo = FALSE&lt;/code&gt; parameter was added to the code chunk to prevent printing of the R code that generated the plot.&lt;/p&gt;
&lt;h2 id=&#34;data-types-and-structures&#34;&gt;Data Types and Structures&lt;/h2&gt;
&lt;h3 id=&#34;data-types&#34;&gt;Data Types&lt;/h3&gt;
&lt;p&gt;Okay, now that we have all of those details out of the way, let&amp;rsquo;s take a look at data structures in &lt;code&gt;R&lt;/code&gt;. As we discussed,&lt;code&gt;R&lt;/code&gt; has six basic types of data: numeric, integer, logical, complex, character, and raw. For this class, we won&amp;rsquo;t bother with complex or raw as you are unlikely to encounter them in your introductory spatial explorations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Numeric&lt;/strong&gt; data are numbers that contain a decimal. They can also be whole numbers&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Integers&lt;/strong&gt; are whole numbers (those numbers without a decimal point).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Logical&lt;/strong&gt; data take on the value of either &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;. There’s also another special type of logical called &lt;code&gt;NA&lt;/code&gt; to represent missing values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Character data&lt;/strong&gt; represent string values. You can think of character strings as something like a word (or multiple words). A special type of character string is a factor, which is a string but with additional attributes (like levels or an order). Factors become important in the analyses and visualizations we&amp;rsquo;ll attempt later in the course.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are a variety of ways to learn more about the structure of different data types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class()&lt;/code&gt; - returns the type of object (high level)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;typeof()&lt;/code&gt; - returns the type of object (low level)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;length()&lt;/code&gt; tells you about the length of an object&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attributes()&lt;/code&gt; - does the object have any metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;num &amp;lt;- 2.2
class(num)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;typeof(num)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;double&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;y &amp;lt;- 1:10 
y
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(y)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;typeof(y)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(y)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;b &amp;lt;- &amp;quot;3&amp;quot;
class(b)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;is.numeric(b)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;c &amp;lt;- as.numeric(b)
class(c)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;data-structures&#34;&gt;Data Structures&lt;/h3&gt;
&lt;p&gt;You can store information in a variety of ways in &lt;code&gt;R&lt;/code&gt;. The types we are most likely to encounter this semester are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Vectors&lt;/strong&gt;: a collection of elements that are typically &lt;code&gt;character&lt;/code&gt;, &lt;code&gt;logical&lt;/code&gt;, &lt;code&gt;integer&lt;/code&gt;, or &lt;code&gt;numeric&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#sometimes we&#39;ll need to make sequences of numbers to facilitate joins
series &amp;lt;- 1:10
series.2 &amp;lt;- seq(10)
series.3 &amp;lt;- seq(from = 1, to = 10, by = 0.1)
series
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;series.2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;series.3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1.0  1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4
## [16]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9
## [31]  4.0  4.1  4.2  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4
## [46]  5.5  5.6  5.7  5.8  5.9  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9
## [61]  7.0  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4
## [76]  8.5  8.6  8.7  8.8  8.9  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9
## [91] 10.0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;c(series.2, series.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1]  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0 10.0  1.0  1.1  1.2  1.3  1.4
##  [16]  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9
##  [31]  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.0  4.1  4.2  4.3  4.4
##  [46]  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9
##  [61]  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.0  7.1  7.2  7.3  7.4
##  [76]  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9
##  [91]  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9 10.0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(series.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;typeof(series.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;double&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(series.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 91
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Missing Data: R supports missing data in most of the data structures we use, but they can lead to some strange behaviors. Here are a few ways to find missing data:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- c(&amp;quot;a&amp;quot;, NA, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;, NA)
is.na(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE  TRUE FALSE FALSE  TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;anyNA(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Matrices&lt;/strong&gt;: are an extension of the numeric or character vectors. They are not a separate type of object but simply an atomic vector with dimensions; the number of rows and columns. As with atomic vectors, the &lt;em&gt;elements of a matrix must be of the same data&lt;/em&gt;. Matrices are the foundation of rasters, which we&amp;rsquo;ll be discussing frequently throughout the course&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#matrices are filled columnwise in R
m &amp;lt;- matrix(1:6, nrow = 2, ncol = 3)
dim(m)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- 1:3
y &amp;lt;- 10:12

a &amp;lt;- cbind(x, y)
dim(a)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;a[3,1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## x 
## 3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;b &amp;lt;- rbind(x, y)
dim(b)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;b[1,3]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## x 
## 3
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Lists&lt;/strong&gt;: Lists essentially act like containers in &lt;code&gt;R&lt;/code&gt; - they can hold a variety of different data types and structures including more lists. We use lists a lot for functional programming in R where we can apply a function to each element in a list. We&amp;rsquo;ll see this with extracting values from multiple rasters. We can extract elements of lists usin &lt;code&gt;[]&lt;/code&gt; and &lt;code&gt;[[]]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- list(1, &amp;quot;a&amp;quot;, TRUE, 1+4i)
x
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1
## 
## [[2]]
## [1] &amp;quot;a&amp;quot;
## 
## [[3]]
## [1] TRUE
## 
## [[4]]
## [1] 1+4i
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#adding names
xlist &amp;lt;- list(a = &amp;quot;Waldo&amp;quot;, b = 1:10, data = head(mtcars))
xlist
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] &amp;quot;Waldo&amp;quot;
## 
## $b
##  [1]  1  2  3  4  5  6  7  8  9 10
## 
## $data
##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xlist[[1]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Waldo&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xlist[[3]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xlist[[3]][1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    mpg
## Mazda RX4         21.0
## Mazda RX4 Wag     21.0
## Datsun 710        22.8
## Hornet 4 Drive    21.4
## Hornet Sportabout 18.7
## Valiant           18.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xlist[[3]][1,2]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xlist[3][1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $data
##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Frames&lt;/strong&gt;: data frames resemble that tabular datasets you might be used to in spreadsheet programs and are probably one of the most common types of data in &lt;code&gt;R&lt;/code&gt;. A data frame is a special type of list where every element has the same length (but can have different types of data). We&amp;rsquo;ll be reading in a number of data frames for this first assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat &amp;lt;- data.frame(id = letters[1:10], x = 1:10, y = 11:20)
dat
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    id  x  y
## 1   a  1 11
## 2   b  2 12
## 3   c  3 13
## 4   d  4 14
## 5   e  5 15
## 6   f  6 16
## 7   g  7 17
## 8   h  8 18
## 9   i  9 19
## 10  j 10 20
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;is.list(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#lots of ways to look at data in data frames
str(dat) #compact summary of the structure of a dataframe
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	10 obs. of  3 variables:
##  $ id: chr  &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot; &amp;quot;d&amp;quot; ...
##  $ x : int  1 2 3 4 5 6 7 8 9 10
##  $ y : int  11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(dat) #gives the first 6 rows similar to tail()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id x  y
## 1  a 1 11
## 2  b 2 12
## 3  c 3 13
## 4  d 4 14
## 5  e 5 15
## 6  f 6 16
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10  3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;colnames(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;id&amp;quot; &amp;quot;x&amp;quot;  &amp;quot;y&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## accessing elements of a dataframe
dat[1,3]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat[[&amp;quot;y&amp;quot;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat$y
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tibbles&lt;/strong&gt;: are similar to data frames, but allow for lists &lt;em&gt;within&lt;/em&gt; columns. They are designed for use with the &lt;code&gt;tidyverse&lt;/code&gt; (which we&amp;rsquo;ll explore more in future classes), but the primary reason for introducing them here is because they are the foundation of &lt;code&gt;sf&lt;/code&gt; objects which we&amp;rsquo;ll use frequently in the weeks to come.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.3     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.1     ✓ forcats 0.5.1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat.tib &amp;lt;- tibble(dat)
is.list(dat.tib)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;class(dat.tib)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#lots of ways to look at data in data frames
str(dat.tib) #compact summary of the structure of a dataframe
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [10 × 3] (S3: tbl_df/tbl/data.frame)
##  $ id: chr [1:10] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot; &amp;quot;d&amp;quot; ...
##  $ x : int [1:10] 1 2 3 4 5 6 7 8 9 10
##  $ y : int [1:10] 11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(dat.tib) #gives the first 6 rows similar to tail()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 3
##   id        x     y
##   &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 a         1    11
## 2 b         2    12
## 3 c         3    13
## 4 d         4    14
## 5 e         5    15
## 6 f         6    16
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dim(dat.tib)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10  3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;colnames(dat.tib)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;id&amp;quot; &amp;quot;x&amp;quot;  &amp;quot;y&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## accessing elements of a dataframe
dat.tib[1,3]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##       y
##   &amp;lt;int&amp;gt;
## 1    11
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat.tib[[&amp;quot;y&amp;quot;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat.tib$y
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 11 12 13 14 15 16 17 18 19 20
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many of the packages used for spatial operations in &lt;code&gt;R&lt;/code&gt; rely on special objects (e.g., &lt;code&gt;Spatial*&lt;/code&gt;, &lt;code&gt;RasterLayer&lt;/code&gt;) that are combinations of these various elemental data types. That is why we are taking a little time to understand them before jumping into spatial data.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
